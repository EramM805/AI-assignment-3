{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/EramM805/AI-assignment-3/blob/main/Manasia_Assignment3.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset I chose to work with is about [life expectancy of the world](https://www.kaggle.com/amansaxena/lifeexpectancy). The data contains 223 rows with countries and their corresponding life expectancy rank, name, life expectancy overall as well as life expectancy of males and females and the continent the country is in. The data was scraped from [wikipedia](https://en.wikipedia.org/wiki/List_of_countries_by_life_expectancy#List_by_the_CIA_.282016.29). I was interested in this dataset mainly because life expectancy has been a topic discussed for several years especially recently because of covid. This data seemed to be a perfect dataset for both linear regression and classification which is why it was chosen. The dataset also has a usability score of 9.1 on kaggle which is higher than other datasets in the life expectancy topic. \n",
    "\n",
    "In the description of the dataset the original author Aman Saxena (@amansaxena on kaggle) mentions that we can do \"classification by various techniques like SVM(linear), KNN, C.45 etc. and other supervised and unsupervised techniques.\" Using the author's suggestion linear support vector machines and k-nearest neighbor algorithms will be used for classificiation. Over the course of this notebook I hope to find whether male life expectancy is correlated to female life expectency. I will also be looking into whether we can successfully classify what continents each row in the dataset belongs in based on female and male life expectancy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: Regression Dataset Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are six columns in this dataset and 223 rows. The first column is the life expectancy rank which is based on the overall life expectancy. The datatype for rank is integer. The second column is the country name and the datatype is object as strings are objects in python. There are 233 unique values for the country column. The third column is the overall life expectancy which is a float. This column includes the life expectancy of both females and males. The next two columns are female and male life expectancy which are both floats. The last column is the continent the corresping country. The continents used in this dataset are: Africa, Asia, Oceania, North America, South America, and Europe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/EramM805/AI-assignment-3/main/data/Life_expectancy_dataset.csv\", encoding='latin-1')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will show the head of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the head of the dataset we can see that Monaco a country in Europe seems to have the highest overall life expectancy of 89.5. The female life expectancy for all the rows in the head seem to be higher than male life expectancy which is an interesting observation. Also there are only two continents represented in the head which are Europe and Asia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regression we will only be using two columns, male and female life expectancy. Below, I use male life expectancy as the outcome or dependent variable. Because our data has only one feature ```reshape(-1, 1)``` is applied to provide a 2D array as per the documentation for sklearn linear regression.\n",
    "\n",
    "I assume that there is a high correlation between the two but let's see if that is actually the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_female = df[\"Female Life\"]\n",
    "y_male = df[\"Male Life\"]\n",
    "x_female = x_female.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets start with male being the outcome variable. Below we split the cleaned dataset using sklearn into a tratining and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_female, X_test_female, y_train_male, y_test_male = train_test_split(x_female, y_male, test_size=0.33, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we fit a linear regresstion to our training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train_female, y_train_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the regressor with the training set is graphed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train_female, y_train_male, color = 'red')\n",
    "plt.plot(X_train_female, reg.predict(X_train_female), color = 'blue')\n",
    "plt.title('Female life expectancy vs Male life expectancy (Training set)')\n",
    "plt.xlabel('Female life expectancy')\n",
    "plt.ylabel('Male life expectancy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the regressor with both the test and training data set is graphed. The red dots indicate that that specific point belongs to the training set and the green dots indicate that the specific point belongs to test dataset. The blue line is the regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train_female, y_train_male, color = 'red')\n",
    "plt.scatter(X_test_female, y_test_male, color = 'green')\n",
    "plt.plot(X_train_female, reg.predict(X_train_female), color = 'blue')\n",
    "plt.title('Female life expectancy vs Male life expectancy (Test and Training set)')\n",
    "plt.xlabel('Female life expectancy')\n",
    "plt.ylabel('Male life expectancy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take a deeper look at the regressor, a graph is created with the prediction outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction_male = reg.predict(X_test_female)\n",
    "plt.scatter(X_test_female, y_test_male,  color='black')\n",
    "plt.plot(X_test_female, y_prediction_male, color='blue', linewidth=3)\n",
    "plt.title('Female life expectancy vs Male life expectancy (Prediction)')\n",
    "plt.xlabel('Female life expectancy')\n",
    "plt.ylabel('Male life expectancy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the graphs we can obersve that most of the data points fall on the regressor but let's confirm that with our error analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 score is: \", r2_score(y_test_male, y_prediction_male))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r2_score``` is the coefficient of determination of the prediction. Since the score is 0.9554680133599146 where 1.0 is the best possible outcome, it can be determined that the linear regression does perform really well and that the data is highly correlated. However, there are other factors that need to be included for life expectancy other than gender and sexual identity such as vaccination availability, environment, genetics, and drug usage which is why the value is not 1.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Classification Dataset Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns that are in this dataframe have already been discussed above and the dataset head has already been shown. The columns that will be used in the classification are:  \n",
    "- Female life expectancy: Range is from 51 to 93.5\n",
    "- Male life expectancy: Range is from 48.6 to 85.6\n",
    "- Continents: Continents are Africa, Asia, Oceania, North America, South America, and Europe.\n",
    "\n",
    "The continents will be mapped to the following set of integers:\n",
    "- \"Africa\": 0\n",
    "- \"Asia\":1 \n",
    "- \"Oceania\":2\n",
    "- \"North America\":3\n",
    "- \"South America\":4\n",
    "- \"Europe\":5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will do the mapping of the continent column to integers. We will also extract female and male life expectancy from our dataframe so that we are only working with the three columns discussed above. No further cleaning is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[[\"Female Life\", \"Male Life\"]]\n",
    "def convertToInt(y):\n",
    "    intMap = {\"Africa\": 0, \"Asia\":1 , \"Oceania\":2, \"North America\":3, \"South America\":4,  \"Europe\":5 }\n",
    "    output = []\n",
    "    for row in y:\n",
    "        output.append(intMap[row])\n",
    "    return output\n",
    "y = np.array(convertToInt(df[\"Continent\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two classification algorithms will be explored on this dataset. The first that will be discussed is linear support vector machines.\n",
    "\n",
    "Below we split the cleaned dataset using sklearn into a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33 , random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we fit a classifier to our training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that the score of the classifier is only 0.527 which is much lower than our regressor score. The best possible score is 1.0 and we are only able to achieve half of that. This could be for multiple reasons. One reason could be unequal distribution of continent data, for example Asia would appear a lot more in the dataset than Oceania. Other reasons may include different environments within the same continent, and different financial stability levels need to be included as a attribute to succesfully classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since SVM performed less than expected, I will now try another classification algorithm, KNN. Below I fit the KNN classifier to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=4)\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I check the score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this also has a low score. Let's try using 1-5 neighbors instead of just 4 to see if that helps us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=i)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    print(f\"Score with {i} neighbors: {neigh.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it doesn't really help in our case. Unfortunately our maximum score still remains low (0.554). This could be because for the same reasons that we had for the SVM classifier. To repeat: \n",
    "```One reason could be unequal distribution of continent data, for example Asia would appear a lot more in the dataset than Oceania. Other reasons may include different environments within the same continent, and different financial stability levels.```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had to do a lot of research to see how I can visualize the decision surface of our classifier. I stumbled upon [this stackoverflow post](https://stackoverflow.com/questions/51495819/how-to-plot-svm-decision-boundary-in-sklearn-python) where the answer from @seralouk helped me visualize. Below is an attempt to visualize both:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: THE FOLLOWING CODE HAS BEEN RETRIEVED FROM : https://stackoverflow.com/questions/51495819/how-to-plot-svm-decision-boundary-in-sklearn-python\n",
    "def make_meshgrid(x, y, h=.02):\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# title for the plots\n",
    "title = ('Decision surface of linear SVC ')\n",
    "# Set-up grid for plotting.\n",
    "X0, X1 = df[\"Female Life\"], df[\"Male Life\"]\n",
    "xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "ax.set_ylabel('Male Life')\n",
    "ax.set_xlabel('Female Life')\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_title(title)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's move on to using the K-nearest neighbor algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=4)\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meshgrid(x, y, h=.02):\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "def plot_contours(ax, neigh, xx, yy, **params):\n",
    "    Z = neigh.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# title for the plots\n",
    "title = ('Decision surface of K-NN')\n",
    "# Set-up grid for plotting.\n",
    "X0, X1 = df[\"Female Life\"], df[\"Male Life\"]\n",
    "xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "plot_contours(ax, neigh, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "ax.set_ylabel('Male Life')\n",
    "ax.set_xlabel('Female Life')\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "ax.set_title(title)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my report I performed a linear regression to see if there is a correlation between female and life expectancy. using the sklearn library. The linear regression model had a r2 score of ~0.95 which showed that there is a high correlation between female and male life expectancy. It was interesting to prove that they are highly correlated but also realize that there are other factors that go into life expectancy that is not represented in this dataset. If I could extend the linear regression part of this project further I would find more attributes such as healthcare quality or food produce quality to see the relationship between these variables and life expectancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also performed two classification algorithms, SVM and KNN to see if given female and male life expectancy can we successfully predict what continent that data point belongs to. Both models had a low r2 score of ~0.55. This could be for many reasons including unequal data distribution. It was interesting to find different algorithms to use for this part of the project as SVM had failed the first time. If I could extend this project further I would attempt to find a classification model that successfully could classify data points to continents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
